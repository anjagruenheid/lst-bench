{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "directory_path = os.path.abspath(os.path.join('../utils/'))\n",
    "if directory_path not in sys.path:\n",
    "    sys.path.append(directory_path)\n",
    "from functions import *\n",
    "from constant import *\n",
    "\n",
    "# Experiment parameters, need to be set before running this notebook.\n",
    "EXPERIMENT_ID = [\"spark_del_sf_1000\"]  \n",
    "EXPERIMENT_START_TIME = [\"2023-06-29T14:39:03.335772Z\"]\n",
    "#PHASE_IDS = [\"single_user_1_data_maintenance_1\", \"single_user_2_optimize_1\", \"single_user_2o_data_maintenance_2\", \"single_user_3_optimize_2\", \"single_user_3o_data_maintenance_3\", \"single_user_4_optimize_3\"]\n",
    "PHASE_IDS = [\"single_user_1_data_maintenance_1\", \"single_user_2o_data_maintenance_2\", \"single_user_3o_data_maintenance_3\"]\n",
    "\n",
    "# Only one task type can be set, use prefixes such as 'single_user' or 'data_maintenance'. All executions times of a task prefix within a phase are summed up.\n",
    "TASK_PREFIX = \"single_user\"\n",
    "TASK_ABBRV = \"SU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check input validity and create DB connection --- #\n",
    "assert len(EXPERIMENT_ID)==len(EXPERIMENT_START_TIME)\n",
    "\n",
    "# Connect to database.\n",
    "con = duckdb.connect(database=DUCKDB_PATH, read_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data manipulations --- #\n",
    "\n",
    "# Retrieve relevant data.\n",
    "EXP_DATA = pd.DataFrame()\n",
    "for idx, id in enumerate(EXPERIMENT_ID):\n",
    "    EXP_DATA = pd.concat([EXP_DATA, retrieve_grouped_event_df(con, id, EXPERIMENT_START_TIME[idx], PHASE_IDS)])\n",
    "    EXP_DATA[\"exp_name\"] = id\n",
    "EXP_DATA = filterByEventType(EXP_DATA, \"EXEC_TASK\")\n",
    "EXP_DATA = filterByEventPrefix(EXP_DATA, TASK_PREFIX)\n",
    "\n",
    "# Create labels for tasks.\n",
    "for idx, value in enumerate(EXP_DATA['group_name'].unique()):\n",
    "        EXP_DATA.loc[EXP_DATA[\"group_name\"] == value, \"task_id\"] = TASK_ABBRV + \"-\" + str(idx + 1)\n",
    "\n",
    "# Calculate latency for each element.\n",
    "EXP_DATA['time_diff_in_mins'] = EXP_DATA.apply(lambda x: time_diff_in_minutes(x['event_start_time'], x['event_end_time']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(str):\n",
    "    if 'Del' in str or 'DBX' in str or 'del' in str:\n",
    "        return 'Delta'\n",
    "    elif 'ib' in str and 'cow' in str:\n",
    "        return 'Iceberg (CoW)'\n",
    "    elif 'ib' in str and 'mor' in str:\n",
    "        return 'Iceberg (MoR)'\n",
    "    elif 'hudi' in str and 'cow' in str:\n",
    "        return 'Hudi (CoW)'\n",
    "    elif 'hudi' in str and 'mor' in str:\n",
    "        return 'Hudi (MoR)'\n",
    "\n",
    "def get_dashes_val(str):\n",
    "    if 'Delta' in str:\n",
    "        return (1,0)\n",
    "    elif 'Iceberg (CoW)' in str and 'CoW' in str:\n",
    "        return (1,0)\n",
    "    elif 'Iceberg (MoR)' in str and 'MoR' in str:\n",
    "        return (1,1)\n",
    "    elif 'Hudi (CoW)' in str:\n",
    "        return (1,0)\n",
    "    elif 'Hudi (MoR)' in str:\n",
    "        return (1,1)\n",
    "\n",
    "def get_markers_val(str):\n",
    "    if 'Delta' in str:\n",
    "        return 'X'\n",
    "    elif 'Iceberg (CoW)' in str and 'CoW' in str:\n",
    "        return 'X'\n",
    "    elif 'Iceberg (MoR)' in str and 'MoR' in str:\n",
    "        return 'P'\n",
    "    elif 'Hudi (CoW)' in str:\n",
    "        return 'X'\n",
    "    elif 'Hudi (MoR)' in str:\n",
    "        return 'P'\n",
    "\n",
    "EXP_DATA['ExpLabel'] = EXP_DATA.apply(lambda x: get_name(x['exp_name']), axis=1)\n",
    "\n",
    "custom_palette = {}\n",
    "custom_palette['Delta'] = 'red'\n",
    "custom_palette['Hudi (CoW)'] = 'green'\n",
    "custom_palette['Hudi (MoR)'] = 'green'\n",
    "custom_palette['Iceberg (CoW)'] = 'blue'\n",
    "custom_palette['Iceberg (MoR)'] = 'blue'\n",
    "\n",
    "dashes = []\n",
    "markers = []\n",
    "for palette_key in custom_palette.keys():\n",
    "    dashes.append(get_dashes_val(palette_key))\n",
    "    markers.append(get_markers_val(palette_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data appropriately.\n",
    "grouped_df = EXP_DATA.groupby(['task_id','ExpLabel'], as_index=False)['time_diff_in_mins'].sum()\n",
    "\n",
    "# --- Plot the data --- #\n",
    "sns.set(rc={'figure.figsize':(8,3)})\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot latency (in order of ids).\n",
    "sns.lineplot(x='task_id', y='time_diff_in_mins', hue='ExpLabel', data=grouped_df, palette=custom_palette, errorbar=None, style=\"ExpLabel\", dashes=dashes, markers=markers, linewidth = 2, markersize=10)\n",
    "#plt.legend(loc='upper left')\n",
    "plt.legend().set_visible(False)\n",
    "plt.ylabel(\"Latency (mins)\")\n",
    "plt.xlabel(\"Task ID\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
